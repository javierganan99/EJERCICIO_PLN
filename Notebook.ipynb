{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8931e4d8",
   "metadata": {},
   "source": [
    "## Apartado 1\n",
    "\n",
    "En este primer ejercicio se implementa la función *string addPunctuationBasic(string)* que, dado un string de entrada que contiene palabras en minísculas y sin signos de puntuación, devuelve dicho string con la primera letra en mayúsculas y un punto al final. Para mayor generalidad, consideramos que la frase pueda contener espacios o tabulaciones al final, y si ya contiene un punto final no añadimos otro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1843ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm Francisco Javier Gañán.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addPunctuationBasic(sent):\n",
    "    sent = sent[0].upper() + sent[1:]\n",
    "    while sent[-1] == ' ' or sent[-1] == '\\t' or sent[-1] == '\\n':\n",
    "        sent = sent[0:-1]\n",
    "    if sent[-1] == '.' or sent[-1] == ',' or sent[-1] == '.' or sent[-1] == ':' or sent[-1] == ';' or sent[-1] == '?' or sent[-1] == '!':\n",
    "        return sent\n",
    "    else:\n",
    "        return sent + '.'\n",
    "\n",
    "addPunctuationBasic(\"i'm Francisco Javier Gañán\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e352673",
   "metadata": {},
   "source": [
    "## Apartado 2\n",
    "\n",
    "En este segundo apartado se implementa la función *[(pos, err)] verifyPunctuation(string test, string check)*. Esta función recibe como entrada dos strings y, basándose en la distancia de Levenshtein y en recorrer la matriz que se genera, calcula una lista de mínimas ediciones para convertir *test* en *check*. Se puede encontrar información sobre este algoritmo para calcular la distancia de Levenshtein y la matriz asociada en https://sites.google.com/site/algoritmossimilaridaddistancia/distancia-de-levenshtein. \n",
    "\n",
    "En el modelo original de Levenshtein, que es el se usa en este apartado, cada operación de edición (inserción, sustitución o eliminación) tiene coste 1. Por tanto, la distancia de Levenshtein es la suma del número de ediciones realizadas. Needleman y Wunsch, en 1970, lo modificaron para permitir operaciones de edición con distinto costo. Sin embargo, esto no se considera en este ejercicio, ya que, en general, debería asignarse un costo personalizado a cada pareja de palabras para sustitución, eliminación e inserción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818b280",
   "metadata": {},
   "source": [
    "### Tokenizar\n",
    "\n",
    "La siguiente función (*Tokenize*) se utiliza para tokenizar. Funciona tanto para frases individuales como para textos completos con numerosas frases. Se ha diseñado así para poder tokenizar correctamente los corpus utilizados en este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(seq):\n",
    "        seqToken = [] # Guarda la secuencia tokenizada\n",
    "        ant = 0 # Guarda la posición del carácter desde el que comienza un nuevo token\n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] == ' ' and not (seq[i-1] == ',' or seq[i-1] == '.' or seq[i-1] == ':' or seq[i-1] == ';' or seq[i-1] == '?' or seq[i-1] == '!' or seq[i-1] == ' ' or seq[i-1] == '\\n'):\n",
    "                seqToken.append(seq[ant:i])\n",
    "                ant = i + 1\n",
    "            elif seq[i] == ' ':\n",
    "                ant = i + 1\n",
    "            elif seq[i] == ',' or seq[i] == '.' or seq[i] == ':' or seq[i] == ';' or seq[i] == '?' or seq[i] == '!':\n",
    "                if ant < i:\n",
    "                    seqToken.append(seq[ant:i])\n",
    "                    seqToken.append(seq[i])\n",
    "                    ant = i + 1\n",
    "                else:\n",
    "                    seqToken.append(seq[i])\n",
    "                    ant = i + 1\n",
    "            elif i == len(seq) - 1 and seq[i] != '\\n':\n",
    "                seqToken.append(seq[ant:i+1])\n",
    "\n",
    "            # Para leer textos completos considerando el salto de línea. El salto de línea no se considera como token.\n",
    "            # También se considera que el salto de línea se situa después de un signo de puntuación o de un espacio.\n",
    "            if seq[i] == \"\\n\":\n",
    "                ant = i + 1\n",
    "                \n",
    "        return seqToken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19facda9",
   "metadata": {},
   "source": [
    "### Verificación de la puntuación\n",
    "\n",
    "En la función *verifyPunctuation* se incluyen 3 funciones, que se ejecutan de forma consecutiva:\n",
    "\n",
    "- **Tokenize**: La presentada en la celda anterior, para tokenizar los *strings* de entrada.\n",
    "\n",
    "- **matrizLevenshtein**: Calcula la matriz cuyo último elemento (elemento de coordenadas la última fila y la última columna) es la distancia de Levenshtein. Esta matriz se utiliza para calcular posteriormente la lista de ediciones. \n",
    "\n",
    "- **ediciones**: Calcula la lista de ediciones recorriendo la matriz generada previamente, llamda **M**. **M** se recorre empezando en el último elemento. En cada iteración, mientras *i* y *j* (índices de la matriz de filas y columnas, respectivamente) no sean ambos iguales a 0:\n",
    "    1. Se mira en la vecindad, donde *vecinos* = [**M**(*i -1*, *j*), **M**(*i*, *j - 1*), **M**(*i - 1*, *j - 1*)].\n",
    "    2. Si el valor de algún vecino es igual a **M**(*i*,*j*), se actualizan *j = j - 1* y *i = i - 1*.\n",
    "       Si no, se selecciona el valor mínimo de todos los vecinos, y se añade a la lista de ediciones la operación correspondiente (en función de las coordenadas del vecino de valor mínimo):\n",
    "\n",
    "       - ( *i -1*, *j* ) -> ( 'D',*i* ): Se añade una eliminación a la lista de ediciones. Dicha eliminación se incluye en la lista junto con el índice *i*, que se corresponde con el *string* de *check* en este trabajo. \n",
    "       - ( *i*, *j - 1* ) -> ( 'I',*i* ): Se añade una inserción. \n",
    "       - ( *i -1*, *j - 1* ) -> ( 'S',*i* ): Se añade una sustitución.\n",
    "\n",
    "       \n",
    "       Finalmente, se actualizan *i* y *j* con las coordenadas del vecino seleccionado.\n",
    "\n",
    "Es importante señalar que este algoritmo genera una de las posibles listas de edición que se pueden conseguir, aunque siempre una de distancia mínima. Esto es porque, al recorrer la matriz, si varios vecinos tienen el mismo valor en el paso 2, se ofrece da la posibilidad de escoger varias secuencias de distancia mínima. El algoritmo escogido para este ejercicio da siempre la misma lista de ediciones para dos secuencias iguales.\n",
    "        \n",
    "\n",
    "Inspiración para **matrizLevenshtein**:\n",
    "https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "\n",
    "Inspiración para **ediciones**:\n",
    "https://gist.github.com/curzona/9435822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4810aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def verifyPunctuation(test, check):\n",
    "    ## Primero se tokenizan las dos secuencias mediante la función Tokenize\n",
    "    checkToken = Tokenize(check)\n",
    "    testToken = Tokenize(test)\n",
    "\n",
    "            \n",
    "    ## A continuación, se calcula la matriz que computa la distancia de Levenshtein\n",
    "    def matrizLevenshtein(token1, token2):\n",
    "        matrix = np.zeros((len(token1) + 1, len(token2) + 1)) # Se crea la matriz\n",
    "        \n",
    "        for t1 in range(len(token1) + 1): # La primera fila contiene los índices de las posiciones del token 1\n",
    "            matrix[t1][0] = t1\n",
    "        \n",
    "        for t2 in range(len(token2) + 1): # La primera columna contiene los índices de las posiciones del token 2\n",
    "            matrix[0][t2] = t2\n",
    "        \n",
    "        for t1 in range(1, len(token1) + 1):\n",
    "            for t2 in range(1, len(token2) + 1):\n",
    "                # Calcuate \n",
    "                if (token1[t1-1] == token2[t2-1]):\n",
    "                    matrix[t1][t2] = matrix[t1 - 1][t2 - 1]\n",
    "                else:\n",
    "                    a = matrix[t1][t2 - 1]\n",
    "                    b = matrix[t1 - 1][t2]\n",
    "                    c = matrix[t1 - 1][t2 - 1]\n",
    "\n",
    "                    if (a <= b and a <= c):\n",
    "                        matrix[t1][t2] = a + 1\n",
    "                    elif (b <= a and b <= c):\n",
    "                        matrix[t1][t2] = b + 1\n",
    "                    else:\n",
    "                        matrix[t1][t2] = c + 1 \n",
    "\n",
    "        return matrix\n",
    "    \n",
    "    matrix_L = matrizLevenshtein(checkToken,testToken)\n",
    "    \n",
    "    ## Se calcula la lista de ediciones\n",
    "    def ediciones(token1, token2, mat):\n",
    "        i,j = len(token1), len(token2)\n",
    "        ediciones = []\n",
    "\n",
    "        while(not (i==0 and j==0)):\n",
    "            p = mat[i][j]\n",
    "            vecinos = []\n",
    "\n",
    "            if (i!=0 and j!=0):\n",
    "                vecinos.append(mat[i-1][j-1])\n",
    "\n",
    "            if (i!=0):\n",
    "                vecinos.append(mat[i-1][j])\n",
    "            \n",
    "            if (j!=0):\n",
    "                vecinos.append(mat[i][j-1])\n",
    "            \n",
    "            min_c = min(vecinos)\n",
    "\n",
    "            if(min_c == p): # No se añadie ninguna edición\n",
    "                i, j = i-1, j-1\n",
    "            elif(j!=0 and min_c == mat[i][j-1]): # Se priorizan las inserciones frente a las sustituciones en el orden para tomar los caminos\n",
    "                i, j = i, j-1\n",
    "                ediciones.append(('I', i))\n",
    "            elif(i!=0 and j!=0 and min_c == mat[i-1][j-1]): # Se priorizan las sustituciones frente a las eliminaciones para tomar los caminos\n",
    "                i, j = i-1, j-1\n",
    "                ediciones.append(('S', i))\n",
    "            elif(i!=0 and min_c == mat[i-1][j]): # Se le da menor prioridad a la hora de escoger los caminos\n",
    "                i, j = i-1, j\n",
    "                ediciones.append(('D', i))\n",
    "\n",
    "        ediciones.reverse() # Como se ha recorrido la matriz a la inversa, se debe invertir la lista para que esté en el orden adecuado\n",
    "        return ediciones\n",
    "\n",
    " \n",
    "    return ediciones(checkToken, testToken, matrix_L) #, len(testToken), len(checkToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b700b",
   "metadata": {},
   "source": [
    "A continuación, se comprueba que la función genera una lista de ediciones adecuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a87feb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('D', 0), ('S', 1), ('D', 4), ('D', 6), ('D', 11)]\n",
      "[('D', 0), ('S', 1), ('S', 2), ('D', 9)]\n",
      "[('S', 1), ('S', 2), ('D', 4), ('D', 6), ('S', 11)]\n"
     ]
    }
   ],
   "source": [
    "edit = verifyPunctuation(\"and if so how do you explain it\", \"And, if so, how, do you explain it?\")\n",
    "print(edit)\n",
    "\n",
    "edit = verifyPunctuation(\"and if so how do you explain it\", \"And? If so how do you explain it.\")\n",
    "print(edit)\n",
    "\n",
    "edit = verifyPunctuation(\"And? If so how do you explain it.\", \"And, if so, how, do you explain it?\")\n",
    "print(edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b66a23",
   "metadata": {},
   "source": [
    "## Apartado 3\n",
    " En este apartado se implementa una función (*calculaMetricas*) que calcula el rendimiento de un algoritmo de puntuación, evaluando su resultado en un corpus sobre el que se itera frase a frase. Las métricas que genera son Precisión, *Recall* y F1. También se prueba dicha función para el algoritmo básico de puntuación del apartado 1 sobre el corpus de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ba761",
   "metadata": {},
   "source": [
    "Lo primero que se hace es leer los corpus de *test* y *check* línea a línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9cf5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Guardamos los textos de test y check por líneas\n",
    "f_test = open(\"datasets/PunctuationTask.test.en\",\"r\")\n",
    "f_check = open(\"datasets/PunctuationTask.check.en\",\"r\")\n",
    "linesTest = f_test.readlines()\n",
    "linesCheck = f_check.readlines()\n",
    "f_test.close()\n",
    "f_check.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96008a2c",
   "metadata": {},
   "source": [
    "A continuación, se calculan las métricas correspondientes. Para ello, es necesario definir los conceptos de TP (*True Positives*), FP (*False Positives*) y FN (*False Negatives*) para un modelo de puntuación. Definimos:\n",
    "\n",
    "-- **TP**: Cambios correctos que hace el modelo. Estos pueden ser, en general, para los modelos de puntuación que consideramos: Poner mayúscula, poner punto, poner coma, poner dos puntos, poner punto y coma, poner interrogación, poner exclamación. Es decir, añade el signo de puntuación correcto o la mayúscula donde debía realizarse dicho cambio.\n",
    "\n",
    "-- **FP**: Cambios incorrectos que hace el modelo cuando no se debía hacer un cambio.\n",
    "\n",
    "-- **FN**: Cambios que omite el modelo que deberían haberse realizado.\n",
    "\n",
    "**NOTA**: Es importante tener en cuenta que, con estas definiciones, si el modelo realiza un cambio erróneo donde había que realizar un cambio, este cambio no se categoriza como **FP**, ni como **TP**. Esto parece un buen criterio, ya que no afecta tan negativamente al resultado del modelo como un **FP** (pues no empeora la distancia de Levenshtein). \n",
    "\n",
    "Por ejemplo: Si el *string* check es \"*Qué buen día hace!*\" y el *string* test es \"qué buen día hace\", realizar el cambio \"qué buen día hace.\" no se considera como un **TP**, pues no ha realizado el cambio correcto. Sin embargo, tampoco se considera un **FP**, pues debía realizarse un cambio en esa posición. Contrariamente, si el cambio realizado fuese \"qué buen día. hace\", este supondría un **FP**, ya que se ha insertado un cambio incorrecto en una posición en la que no se debía realizar ningún cambio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e480737",
   "metadata": {},
   "source": [
    "Para calcular los TP, FP, FN, se sigue el razonamiento ilustrado en la figura.\n",
    "\n",
    "Si se observan los bloques verdes, estos se corresponden *strings*: con la frase de test original, la frase de check, y la frase que se obtiene al aplicarle el modelo de puntuación. Los bloques azules se corresponden con la distancia de Levenstein entre pares de *strings*. \n",
    "\n",
    "Los bloques *verifyPunctuation()* reciben como entrada dos *strings* y devuelven la lista de edición entre ambos. Los bloques *len()* devuelven la longitud de la lista que reciben como entrada, y el bloque *model()* genera los signos de puntuación sobre el *string* de entrada.\n",
    "\n",
    "- Si se compara el *string* de test con el *string* de Check, se obtiene el número de cambios totales que debe hacer el modelo, esto es **Db = TP + FN**. \n",
    "\n",
    "- Si se compara el *string* de test con el *string* del modelo, se obtiene el número de cambios totales que hace el modelo, esto es **Dm = TP + FP**. \n",
    "\n",
    "- Si se compara el *string* del modelo con el *string* de Check, ocurre que:\n",
    "  - **Dcheck** será el resultado de sumar: \n",
    "    1. Los **FN**, pues son los cambios que el modelo no ha detectado, cuyas diferencias se siguen manifestado entre ambos *strings*.\n",
    "    2. Los **FP**, pues son los cambios que el modelo ha hecho indebidamente, que empeoran la distancia de Levenshtein.\n",
    "\n",
    "**TP**, **FP** y **FN** son incógnitas y **Dm**, **Db** y **Dcheck** son conocidas, por lo que se tiene un sistema de ecuaciones de tres incógnitas compatible determinado que permite conocer dichas incógnitas.\n",
    "\n",
    "**NOTA**: Es importante destacar que, si se conoce el número de cambios que realiza el modelo, **Dm**, no es necesatio generar dicho número por comparación de strings. Sin embargo, para hacer esta función de evaluación válida para modelos tipo caja negra, se ha decidido computar **Dm** de esta manera.\n",
    "\n",
    "![Diagrama explicativo](Diagrama_PLN.drawio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80d32139",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Función para calcular las métricas\n",
    "def calculaMetricas(line_test, line_check, model):\n",
    "    ## Iniciaizamos los valores de TP, FP, FN\n",
    "    TP = 0\n",
    "    TP_FP = 0\n",
    "    TP_FN = 0\n",
    "\n",
    "    # Aplicamos el modelo de puntuacion\n",
    "    modificado = model(line_test)\n",
    "    print(line_test)\n",
    "    print(modificado)\n",
    "    print(line_check)\n",
    "    # Calculamos la distancia test-check\n",
    "    cambios_necesarios = verifyPunctuation(line_test,line_check)\n",
    "    cambios_modelo = verifyPunctuation(line_test,modificado)\n",
    "    cambios_finales = verifyPunctuation(modificado,line_check)\n",
    "\n",
    "    TP_FN = len(cambios_necesarios) # TP + FN\n",
    "    TP_FP = len(cambios_modelo) # TP + FP\n",
    "\n",
    "    # Se calculan los TP como las posiciones en las que aparecian cambios \n",
    "    # en cambios_necesarios y no se incluyen en cambios finales\n",
    "    pos_cn = [cn[1] for cn in cambios_necesarios]\n",
    "    pos_cf = [cf[1] for cf in cambios_finales]\n",
    "    TP = sum([1 for c in pos_cn if c not in pos_cf])\n",
    "\n",
    "    FN = TP_FN -TP\n",
    "    FP = TP_FP -TP\n",
    "    return TP, FN, FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0e44e",
   "metadata": {},
   "source": [
    "Finalmente, mediante la función anterior, se calcula la precisión del modelo básico sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = 0 \n",
    "# R = 0\n",
    "# F1 = 0\n",
    "\n",
    "# for (line1, line2) in zip(linesTest,linesCheck):\n",
    "#     evaluation = calculaMetricas(line1, line2, addPunctuationBasic)\n",
    "#     P += evaluation[0]\n",
    "#     R += evaluation[1]\n",
    "#     F1 += evaluation[2]\n",
    "\n",
    "# P /= len(linesTest)\n",
    "# R /= len(linesTest)\n",
    "# F1 /= len(linesTest)\n",
    "\n",
    "# print(\"Precision: \" + str(P))\n",
    "# print(\"Recall: \" + str(R))\n",
    "# print(\"F1: \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83fa81db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9582752855948732\n",
      "Recall: 0.4451815416477898\n",
      "F1: 0.6079367183702329\n"
     ]
    }
   ],
   "source": [
    "TP = 0 \n",
    "FN = 0\n",
    "FP = 0\n",
    "\n",
    "for (line1, line2) in zip(linesTest,linesCheck):\n",
    "    evaluation = calculaMetricas(line1, line2, addPunctuationBasic)\n",
    "    TP += evaluation[0]\n",
    "    FN += evaluation[1]\n",
    "    FP += evaluation[2]\n",
    "\n",
    "P = TP / (TP + FP)\n",
    "R = TP / (TP + FN)\n",
    "F1 = 2 * (P * R) / (P + R)\n",
    "\n",
    "print(\"Precision: \" + str(P))\n",
    "print(\"Recall: \" + str(R))\n",
    "print(\"F1: \" + str(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba7e95",
   "metadata": {},
   "source": [
    "## Apartado 4\n",
    "\n",
    "En este apartado se realizan dos tareas: \n",
    "\n",
    "- Se crea un modelo de puntuación basado en pseudo-cuatrogramas: Este modelo decidirá, en función de las tres palabras anteriores, si realizar una de las siguientes operaciones: Poner la palabra en mayúscula, poner la palabra en minúscula o añadir un signo de puntuación.\n",
    "\n",
    "- Una función que, utilizando dicho modelo, realice la operación adecuada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30f360",
   "metadata": {},
   "source": [
    "El modelo se genera a partir de un texto tokenizado, realizando los siguientes pasos:\n",
    "\n",
    "1. Se crean cuatrogramas de la siguiente forma: (**token1**, **token2**, **token3**, **operación**). Esto se hace recorriendo el texto tokenizado de cuatro en cuatro y, para el último token, sustituir el contenido por la "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19b66c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudoCuatroGramas(Token):\n",
    "    # Creamos una lista con los pseudo 4-gramas\n",
    "    cuatroGramas = []\n",
    "    for i in range(4, len(Token)):\n",
    "        c_g = Token[(i - 4):i]   \n",
    "        if c_g[-1][0].islower():\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 0])\n",
    "        elif c_g[-1][0].isupper():\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 1])\n",
    "        elif c_g[-1][0] == '.':\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 2])\n",
    "        elif c_g[-1][0] == ',':\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 3])\n",
    "        elif c_g[-1][0] == ':':\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 4])\n",
    "        elif c_g[-1][0] == ';':\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 5])\n",
    "        elif c_g[-1][0] == '?':\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 6])\n",
    "        elif c_g[-1][0] == '!':\n",
    "            cuatroGramas.append([tuple(Token[i - 4:i-1]), 7])\n",
    "    print(cuatroGramas[:200])\n",
    "    return cuatroGramas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = open(\"datasets/PunctuationTask.train.en\",\"r\")\n",
    "linesTrain = f_train.read() # Guardamos el conjunto de entrenamiento\n",
    "f_train.close()\n",
    "trainToken = Tokenize(linesTrain)\n",
    "cuatroGramas = pseudoCuatroGramas(trainToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "314efb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un diccionario para almacenar los tokens únicos y su valor\n",
    "fDist = dict()\n",
    "for cg in cuatroGramas:\n",
    "    if tuple(cg) in fDist:\n",
    "        fDist[tuple(cg)] += 1\n",
    "    else:\n",
    "        fDist[tuple(cg)] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a21f96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se crea la función que añade los signos de puntuación\n",
    "\n",
    "def addPunctuation4gram(sent, addMayusc = True, addDot = True):\n",
    "    sentToken = Tokenize(sent)\n",
    "\n",
    "    # Para añadir la primera palabra en mayúscula\n",
    "    if addMayusc:\n",
    "        sentToken[0] = sentToken[0].capitalize()\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sentToken) - 2:\n",
    "        valor = tuple(sentToken[i:i + 3])\n",
    "        max = 0\n",
    "        max_index = 0\n",
    "        flag = False\n",
    "        for j in range(8):\n",
    "            if tuple([valor, j]) in fDist:\n",
    "                flag = True\n",
    "                act = fDist[tuple([valor, j])]\n",
    "            else:\n",
    "                continue\n",
    "            if act > max:\n",
    "                max = act\n",
    "                max_index = j\n",
    "        \n",
    "        if flag == True:\n",
    "            # Dependiendo del valor máximo, se eliige una acción u otra\n",
    "            if max_index == 0 and (i + 3) < len(sentToken) and not sentToken[i+3].islower():\n",
    "                sentToken[i+3] = sentToken[i+3][0].lower() + sentToken[i+3][1:]\n",
    "            if max_index == 1 and (i + 3) < len(sentToken):\n",
    "                sentToken[i+3] = sentToken[i+3].capitalize() \n",
    "            elif max_index == 2:\n",
    "                sentToken.insert(i+3, '.') \n",
    "            elif max_index == 3:\n",
    "                sentToken.insert(i+3, ',') \n",
    "            elif max_index == 4:\n",
    "                sentToken.insert(i+3, ':')    \n",
    "            elif max_index == 5:\n",
    "                sentToken.insert(i+3, ';') \n",
    "            elif max_index == 6:\n",
    "                sentToken.insert(i+3, '?') \n",
    "            elif max_index == 7:\n",
    "                sentToken.insert(i+3, '!')\n",
    "            elif addDot and (i + 3) == len(sentToken) and sentToken[i+2] not in ['.', '?', '!']:\n",
    "                sentToken.insert(i+3, '.') \n",
    "        elif addDot and (i + 3) == len(sentToken) and sentToken[i+2] not in ['.', '?', '!']:\n",
    "            sentToken.insert(i+3, '.')\n",
    "\n",
    "        i += 1\n",
    "    sentReturn = ''\n",
    "    for k, i in enumerate(sentToken):\n",
    "        if i == ',' or i == '.' or i == ':' or i == ';' or i == '?' or i == '!' or k == 0:\n",
    "            sentReturn = sentReturn + i\n",
    "        else:\n",
    "            sentReturn = sentReturn + ' ' + i\n",
    "    return sentReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa6874",
   "metadata": {},
   "source": [
    "## Apartado 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = 0 \n",
    "# R = 0\n",
    "# F1 = 0\n",
    "\n",
    "# for (line1, line2) in zip(linesTest[:10],linesCheck[:10]):\n",
    "#     evaluation = calculaMetricas(line1, line2, addPunctuation4gram)\n",
    "#     P += evaluation[0]\n",
    "#     R += evaluation[1]\n",
    "#     F1 += evaluation[2]\n",
    "\n",
    "# P /= len(linesTest)\n",
    "# R /= len(linesTest)\n",
    "# F1 /= len(linesTest)\n",
    "\n",
    "# print(\"Precision: \" + str(P))\n",
    "# print(\"Recall: \" + str(R))\n",
    "# print(\"F1: \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de602589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it can be a very complicated thing the ocean \n",
      "\n",
      "It can be a very complicated thing, the ocean.\n",
      "It can be a very complicated thing, the ocean. \n",
      "\n",
      "and we're making the ocean pretty unhappy in a lot of different ways \n",
      "\n",
      "And we're making the ocean pretty unhappy in a lot of different ways.\n",
      "And we're making the ocean pretty unhappy in a lot of different ways. \n",
      "\n",
      "people working in these canneries could barely stay there all day because of the smell but you know what they came out saying \n",
      "\n",
      "People working in these canneries could barely stay there all day because of the smell. But you know, what they came out saying.\n",
      "People working in these canneries could barely stay there all day because of the smell, but you know what they came out saying? \n",
      "\n",
      "we made the ocean unhappy we made people very unhappy and we made them unhealthy \n",
      "\n",
      "We made the ocean unhappy we made people very unhappy and we made them unhealthy.\n",
      "We made the ocean unhappy; we made people very unhappy, and we made them unhealthy. \n",
      "\n",
      "we see the base of the food chain the plankton the small things and we see how those animals are food to animals in the middle of the pyramid and on so up this diagram \n",
      "\n",
      "We see the base of the food chain the plankton the small things and we see how those animals are food to animals in the middle of the pyramid and on so up this diagram.\n",
      "We see the base of the food chain, the plankton, the small things, and we see how those animals are food to animals in the middle of the pyramid, and on so up this diagram. \n",
      "\n",
      "now a dolphin mother dolphin any dolphin -- there's only one way that a pcb can get out of a dolphin \n",
      "\n",
      "Now a dolphin mother dolphin any dolphin -- there's only one way that a pcb can get out of a dolphin.\n",
      "Now, a dolphin, mother dolphin, any dolphin -- there's only one way that a PCB can get out of a dolphin. \n",
      "\n",
      "and what's that \n",
      "\n",
      "And what's that.\n",
      "And what's that? \n",
      "\n",
      "here's a diagram of the pcb load of dolphins in sarasota bay \n",
      "\n",
      "Here's a diagram of the pcb load of dolphins in sarasota bay.\n",
      "Here's a diagram of the PCB load of dolphins in Sarasota Bay. \n",
      "\n",
      "and we also are eating meat that comes from some of these same places \n",
      "\n",
      "And we also are eating meat, that comes from some of these same places.\n",
      "And we also are eating meat that comes from some of these same places. \n",
      "\n",
      "that's a tragedy for those populations but it's also a tragedy for the people eating them because they don't know that that's toxic meat \n",
      "\n",
      "That's a tragedy for those populations but it's also a tragedy for the people eating them because they don't know that that's toxic meat.\n",
      "That's a tragedy for those populations, but it's also a tragedy for the people eating them because they don't know that that's toxic meat. \n",
      "\n",
      "Precision: 0.76\n",
      "Recall: 0.5277777777777778\n",
      "F1: 0.6229508196721312\n"
     ]
    }
   ],
   "source": [
    "TP = 0 \n",
    "FN = 0\n",
    "FP = 0\n",
    "\n",
    "for (line1, line2) in zip(linesTest[:10],linesCheck[:10]):\n",
    "    evaluation = calculaMetricas(line1, line2, addPunctuation4gram)\n",
    "    TP += evaluation[0]\n",
    "    FN += evaluation[1]\n",
    "    FP += evaluation[2]\n",
    "\n",
    "P = TP / (TP + FP)\n",
    "R = TP / (TP + FN)\n",
    "F1 = 2 * (P * R) / (P + R)\n",
    "\n",
    "print(\"Precision: \" + str(P))\n",
    "print(\"Recall: \" + str(R))\n",
    "print(\"F1: \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ea369256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mix_model(sent):\n",
    "#     sent2 = addPunctuation4gram(sent)\n",
    "#     return addPunctuationBasic(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = 0 \n",
    "# R = 0\n",
    "# F1 = 0\n",
    "\n",
    "# for (line1, line2) in zip(linesTest,linesCheck):\n",
    "#     evaluation = calculaMetricas(line1, line2, mix_model)\n",
    "#     P += evaluation[0]\n",
    "#     R += evaluation[1]\n",
    "#     F1 += evaluation[2]\n",
    "\n",
    "# P /= len(linesTest)\n",
    "# R /= len(linesTest)\n",
    "# F1 /= len(linesTest)\n",
    "\n",
    "# print(\"Precision: \" + str(P))\n",
    "# print(\"Recall: \" + str(R))\n",
    "# print(\"F1: \" + str(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a266a",
   "metadata": {},
   "source": [
    "## Apartado 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9091dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiamos los textos para que puedan ser leídos por el modelo\n",
    "f_test = open(\"datasets/PunctuationTask.test.en\",\"r\")\n",
    "f_check = open(\"datasets/PunctuationTask.check.en\",\"r\")\n",
    "f_train = open(\"datasets/PunctuationTask.train.en\",\"r\")\n",
    "Test = f_test.read()\n",
    "Check = f_check.read()\n",
    "Train = f_train.read()\n",
    "f_test.close()\n",
    "f_check.close()\n",
    "f_train.close()\n",
    "\n",
    "Check_new = \"\"\n",
    "for c in Check:\n",
    "    if c == ',' or c == '.' or c == ':' or c == ';' or c == '?' or c == '!':\n",
    "        Check_new += \" \"\n",
    "    Check_new += c\n",
    "\n",
    "Train_new = \"\"\n",
    "for c in Train:\n",
    "    if c == ',' or c == '.' or c == ':' or c == ';' or c == '?' or c == '!':\n",
    "        Train_new += \" \"\n",
    "    Train_new += c\n",
    "\n",
    "\n",
    "with open('datasets/test.txt', 'w') as f:\n",
    "    f.write(Test.lower())\n",
    "f.close()\n",
    "with open('datasets/dev.txt', 'w') as f:\n",
    "    f.write(Check_new.lower())\n",
    "f.close()\n",
    "with open('datasets/train.txt', 'w') as f:\n",
    "    f.write(Train_new.lower())\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "55c4f13588671055eddbcd88b1478edc188b631075a8eed8f2c844334309e5e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
